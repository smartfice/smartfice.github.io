{"meta":{"title":"Monkey'blog","subtitle":"welcome to monkey","description":"smartfice python","author":"smartfice","url":"http://smartfice.com"},"pages":[{"title":"分类","date":"2017-10-08T08:55:36.000Z","updated":"2017-10-08T08:56:34.887Z","comments":true,"path":"categories/index.html","permalink":"http://smartfice.com/categories/index.html","excerpt":"","text":""},{"title":"images","date":"2017-10-05T13:58:38.000Z","updated":"2017-10-05T13:58:38.059Z","comments":true,"path":"images/index.html","permalink":"http://smartfice.com/images/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-10-08T08:57:16.000Z","updated":"2017-10-08T08:57:47.425Z","comments":true,"path":"tags/index.html","permalink":"http://smartfice.com/tags/index.html","excerpt":"","text":""},{"title":"about","date":"2017-09-30T06:51:06.000Z","updated":"2017-09-30T06:51:06.629Z","comments":true,"path":"about/index.html","permalink":"http://smartfice.com/about/index.html","excerpt":"","text":""}],"posts":[{"title":"Redis事务和持久化","slug":"redis","date":"2017-10-09T03:00:24.870Z","updated":"2017-10-09T02:58:58.551Z","comments":true,"path":"redis/","link":"","permalink":"http://smartfice.com/redis/","excerpt":"","text":"本文将介绍Reids的事务，数据持久化等相关知识;Redis事务 用Multi(Start Transaction)、Exec(Commit)、Discard(Rollback)实现。 在事务提交前，不会执行任何指令，只会把它们存到一个队列里，不影响其他客户端的操作。在事务提交时，批量执行所有指令，并且带有以下两个重要的保证： 事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。 1.1 事务用法 MULTI 命令用于开启一个事务，它总是返回OK。MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。 另一方面，通过调用DISCARD，客户端可以清空事务队列，并放弃执行事务。 一个事务从开始到执行会经历以下三个阶段： 开始事务; 命令入队; 执行事务。使用实例如下：123456789101112131415127.0.0.1:6379&gt; MULTI //开启事务OK127.0.0.1:6379&gt; SET minhow 'Redis MySQL' //设置minhow的值QUEUED127.0.0.1:6379&gt; GET minhow //获取minhow的值QUEUED127.0.0.1:6379&gt; SADD name 'minhow' // 添加name集合QUEUED127.0.0.1:6379&gt; SMEMBERS name // 列出集合name的所有元素QUEUED127.0.0.1:6379&gt; EXEC //提交1) OK2) \"Redis MySQL\"3) (integer) 14) 1) \"minhow\" EXEC 命令的回复是一个数组，数组中的每个元素都是执行事务中的命令所产生的回复。其中，回复元素的先后顺序和命令发送的先后顺序一致。 当客户端处于事务状态时，所有传入的命令都会返回一个内容为QUEUED 的状态回复（status reply），这些被入队的命令将在EXEC命令被调用时执行。 1.2 事务中的错误 对于事务的执行来说，如果redis开启了AOF持久化的话，那么一旦事务被成功执行，事务中的命令就会通过write命令一次性写到磁盘中去，如果在向磁盘中写的过程中恰好出现断电、硬件故障等问题，那么就可能出现只有部分命令进行了AOF持久化，这时AOF文件就会出现不完整的情况，这时，我们可以使用redis-check-aof工具来修复这一问题，这个工具会将AOF文件中不完整的信息移除，确保AOF文件完整可用。使用事务时可能会遇上以下两种错误： 事务在执行 EXEC 之前，入队的命令可能会出错。比如说，命令可能会产生语法错误（参数数量错误，参数名错误，等等），或者其他更严重的错误，比如内存不足（如果服务器使用 maxmemory 设置了最大内存限制的话）。 命令可能在 EXEC 调用之后失败。举个例子，事务中的命令可能处理了错误类型的键，比如将列表命令用在了字符串键上面，诸如此类。对于发生在EXEC执行之前的错误，客户端以前的做法是检查命令入队所得的返回值：如果命令入队时返回QUEUED，那么入队成功；否则，就是入队失败。如果有命令在入队时失败，那么大部分客户端都会停止并取消这个事务。不过，从Redis 2.6.5开始，服务器会对命令入队失败的情况进行记录，并在客户端调用EXEC命令时，拒绝执行并自动放弃这个事务。实例如下： 1234567891011121314151617181920127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379&gt; minhow //明显的语法错误(error) ERR unknown command 'minhow'127.0.0.1:6379&gt; SET minhow mmQUEUED127.0.0.1:6379&gt; EXEC(error) EXECABORT Transaction discarded because of previous errors.``` * 拒绝执行，之前出现了错误.而对于发生在EXEC执行之后的错误，Redis则采取了完全不同的策略，即Redis不会理睬这些错误，而是继续向下执行事务中的其他命令。这是因为，对于应用层面的错误，并不是Redis自身需要考虑和处理的问题，所以一个事务中如果某一条命令执行失败，并不会影响接下来的其他命令的执行。实例如下：```sql127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379&gt; SET minhow 'name'QUEUED127.0.0.1:6379&gt; SADD minhow 'name' //minhow不是集合，出错QUEUED127.0.0.1:6379&gt; EXEC //第一条OK，第二条error1) OK2) (error) WRONGTYPE Operation against a key holding the wrong kind of value 最重要的是记住这样一条， 即使事务中有某条/某些命令执行失败了， 事务队列中的其他命令仍然会继续执行 —— Redis 不会停止执行事务中的命令。 1.3 事务不支持回滚 如果你有使用关系式数据库的经验， 那么 “Redis 在事务失败时不进行回滚，而是继续执行余下的命令”这种做法可能会让你觉得有点奇怪。以下是这种做法的优点： Redis 命令只会因为错误的语法而失败（并且这些问题不能在入队时发现），或是命令用在了错误类型的键上面：这也就是说，从实用性的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中。 因为不需要对回滚进行支持，所以 Redis 的内部可以保持简单且快速。 有种观点认为 Redis 处理事务的做法会产生 bug ， 然而需要注意的是， 在通常情况下， 回滚并不能解决编程错误带来的问题。 举个例子， 如果你本来想通过 INCR 命令将键的值加上 1 ， 却不小心加上了 2 ， 又或者对错误类型的键执行了 INCR ， 回滚是没有办法处理这些情况的。 1.4 事务WATCH—乐观锁WATCH命令可以为Redis事务提供check-and-set（CAS）行为。被WATCH的键会被监视，并会发觉这些键是否被改动过了。 如果有至少一个被监视的键在EXEC执行之前被修改了，那么整个事务都会被取消， EXEC返回nil-reply来表示事务已经失败。实例如下：1234567891011121314127.0.0.1:6379&gt; SET minhow 109 //设置minhow的值OK127.0.0.1:6379&gt; WATCH minhow //监视minhowOK127.0.0.1:6379&gt; SET minhow 09 //修改minhow的值OK127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379&gt; SET minhow 9QUEUED127.0.0.1:6379&gt; GET minhowQUEUED127.0.0.1:6379&gt; EXEC //执行失败(nil) WATCH使得EXEC命令需要有条件地执行： 事务只能在所有被监视键都没有被修改的前提下执行， 如果这个前提不能满足的话，事务就不会被执行。 2. Redis持久化 R* edis提供了两种持久化的方式，分别是RDB（Redis DataBase）和AOF（Append Only File）。 RDB，就是在不同的时间点，将Redis存储的数据生成快照并存储到磁盘等介质上； AOF，则是换了一个角度来实现持久化，那就是将redis执行过的所有写指令记录下来，在下次Redis重新启动时，只要把这些写指令从前到后再重复执行一遍，就可以实现数据恢复了，Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大。 其实RDB和AOF两种方式也可以同时使用，在这种情况下，如果Redis重启的话，则会优先采用AOF方式来进行数据恢复，这是因为AOF方式的数据恢复完整度更高。 如果你没有数据持久化的需求，也完全可以关闭RDB和AOF方式，这样的话，Redis将变成一个纯内存数据库，就像memcache一样。 2.1 Redis持久化- -RDBRDB方式，是将Redis某一时刻的数据持久化到磁盘中，是一种快照式的持久化方法。 优点： RDB是一个非常紧凑的文件,它保存了某个时间点得数据集,非常适用于数据集的备份,比如你可以在每个小时报保存一下过去24小时内的数据,同时每天保存过去30天的数据,这样即使出了问题你也可以根据需求恢复到不同版本的数据集。 RDB是一个紧凑的单一文件,很方便传送到另一个远端数据中心或者亚马逊的S3（可能加密），非常适用于灾难恢复。 RDB在保存RDB文件时父进程唯一需要做的就是fork出一个子进程,接下来的工作全部由子进程来做，父进程不需要再做其他IO操作，所以RDB持久化方式可以最大化redis的性能。 与AOF相比,在恢复大的数据集的时候，RDB方式会更快一些。 缺点： 如果你希望在redis意外停止工作（例如电源中断）的情况下丢失的数据最少的话，那么RDB不适合你.虽然你可以配置不同的save时间点(例如每隔5分钟并且对数据集有100个写的操作),是Redis要完整的保存整个数据集是一个比较繁重的工作,你通常会每隔5分钟或者更久做一次完整的保存,万一在Redis意外宕机,你可能会丢失几分钟的数据。 RDB 需要经常fork子进程来保存数据集到硬盘上,当数据集比较大的时候,fork的过程是非常耗时的,可能会导致Redis在一些毫秒级内不能响应客户端的请求.如果数据集巨大并且CPU性能不是很好的情况下,这种情况会持续1秒,AOF也需要fork,但是你可以调节重写日志文件的频率来提高数据集的耐久度。 2.2 Redis持久化- -AOF AOF，英文是Append Only File，即只允许追加不允许改写的文件；通过配置redis.conf中的appendonly yes就可以打开AOF功能。如果有写操作（如SET等），Redis就会被追加到AOF文件的末尾。 优点： 使用AOF 会让你的Redis更加耐久: 你可以使用不同的fsync策略：无fsync,每秒fsync,每次写的时候fsync.使用默认的每秒fsync策略,Redis的性能依然很好(fsync是由后台线程进行处理的,主线程会尽力处理客户端请求),一旦出现故障，你最多丢失1秒的数据. AOF文件是一个只进行追加的日志文件,所以不需要写入seek,即使由于某些原因(磁盘空间已满，写的过程中宕机等等)未执行完整的写入命令,你也也可使用redis-check-aof工具修复这些问题。 Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。 AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单： 举个例子， 如果你不小心执行了 FLUSHALL 命令， 但只要 AOF 文件未被重写， 那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。缺点： 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。 根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB 。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关闭 fsync 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。 不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency）。 2.3 Redis持久化- -如何选择RDB和AOF 一般来说， 你应该同时使用两种持久化功能。 如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化。 有很多用户都只使用 AOF 持久化， 但我们并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外，使用RDB还可以避免之前提到的AOF程序的bug。 3. 总结 本文主要讲解了Redis事务运用实例，以及数据持久化的方式，各自优缺点和如何选择合适的方式等知识.","categories":[{"name":"数据库","slug":"数据库","permalink":"http://smartfice.com/categories/数据库/"}],"tags":[{"name":"nosql","slug":"nosql","permalink":"http://smartfice.com/tags/nosql/"},{"name":"Redis","slug":"Redis","permalink":"http://smartfice.com/tags/Redis/"}]},{"title":"django mysql数据库错误相关问题","slug":"mysql","date":"2017-10-08T10:37:38.895Z","updated":"2017-10-08T10:35:52.251Z","comments":true,"path":"mysql/","link":"","permalink":"http://smartfice.com/mysql/","excerpt":"","text":"1、当我把 DEBUG = True设为False的时候运行 Python manage.py runserver 的时候报错 ： CommandError: You must set settings.ALLOWED_HOSTS if DEBUG is False.解决方案：ALLOWED_HOSTS = [‘127.0.0.1’, ‘localhost’] 2、报错信息： ModelForm Creating a ModelForm without either the ‘fields’ attribute or the ‘exclude’ attributeis prohibited; form AuthorForm needs updating. 解决方案：class AuthorForm(ModelForm):class Meta:model = Authorfields = “all” 3、报错信息： CSRF token missing or incorrect解决方案：第一种方法： 第一步、 在 templete 中, 为每个 POST form 增加一个 {csrf_token 第二步、在 view 中, 使用 django.template.RequestContext 而不是 Context.render_to_response, 默认使用 Context. 需要改成 RequestContext.return render_to_response(‘systemofdingh/modify.html’, {‘form’: orderModelForm(instance=orderModify)},context_instance=RequestContext(request))第二中方法： settings.py 中 MIDDLEWARE_CLASSES 中 注释掉’django.middleware.csrf.CsrfViewMiddleware’ 在你的views.py 的方法上加上 @csrf_exempt 装饰 (需要 from django.views.decorators.csrf import csrf_exempt) You are trying to add a non-nullable field ‘orderID’ to ordermodel without a default; we can&apos;t do that (the database needs something to populate existing rows). Please select a fix: Provide a one-off default now (will be set on all existing rows) Quit, and let me add a default in models.py 解决方案: 删除migrate文件，然后重新来Django :queryset的长度查询： len(queryset)model对象转换成dict : model_to_dict问题：字段修改属性发生错误1&gt;12345&gt;python manage.py makemigrationsYou are trying to add a non-nullable field 'price_monthly' to product without a default; we can't do that (the database needs something to populate existing rows).Please select a fix: 1) Provide a one-off default now (will be set on all existing rows) 2) Quit, and let me add a default in models.pySelect an option: {这个可能是之前已创建了表中的一条记录，之后模型中增加了一个非空的字段，但是原来已经存在的记录没有这个值}2&gt;123&gt;python manage.py migrate... ...raise errorclass(errno, errorvalue)django.db.utils.ProgrammingError: (1146, \"Table 'lab_data.bigdata_postgraduate_research_directions' doesn't exist\") {这个是因为在字段中添加了blank=True或者 null=True引起的}3&gt; 1234567&gt;python manage.py makemigrationsYou are trying to change the nullable field 'job_title' on professor to non-nullable without a default; we can't do that (the database needs something to populate existing rows).Please select a fix: 1) Provide a one-off default now (will be set on all existing rows) 2) Ignore for now, and let me handle existing rows with NULL myself (e.g. adding a RunPython or RunSQL operation in the new migration file before the AlterField operation) 3) Quit, and let me add a default in models.pySelect an option: {这个是将模型中的null=True删除了之后产生的错误}1&gt;原因解释： 1234561. The migrations system is designed so that a single migration can be applied to more than one database. For example, you could have a development version, a staging version, and one or more production versions. That&apos;s whymaking the migration is a distinct step from applying the migration, and whymakemgirations can&apos;t just look at the currently active database to see that it doesn&apos;t have any rows. What if you then try to apply the migration to a database that does?The solution in your case is simple: since there are no rows, option 1 (setting a default on all existing rows) won&apos;t do anything at all. So choose option 1, and any value you like.[Django 1.7.1 requires a Default value for field - but no entry is in database. Why?]2. Django adds a default &quot;id&quot; field to every model, you don&apos;t need an extra &quot;twitbot_id&quot; in your model. If a surrogate primary key is all you need, forget about &quot;twitbot_id&quot; because it will be a duplicate of the auto-generated &quot;id&quot;. Seehttps://docs.djangoproject.com/en/dev/topics/db/models/#automatic-primary-key-fieldsIf you add this and you already have TwitterBot objects in your database you must provide a default value to populate this column for existing rows in the database.[Can&apos;t seem to lose this error: “You are trying to add a non-nullable field”] 如果你跟我一样是因为之前建好表a后，又创建一个表b作为a的父类，a中只有pass，那么因为表a已经创建，其中有数据，当a迁移时就会出现新表不能为null且没有指定默认值时就会出现这种错误。 解决方案：1&gt;在基类b中添加允许为空或者添加默认值，并设置b不建表（meta中的abstract = true）12345678910class Base(models.Model): ''' 基类 ''' title = models.CharField(max_length=150, null=True) content = models.TextField(null=True) time_stamp = models.DateTimeField(auto_now_add=True, default=timezone.now()) link = models.URLField(blank=True, verbose_name='url_link') class Meta: abstract = True Note:DataTimeField好像与其它的不一样，不好改！1&gt;2&gt;3&gt;删除所有migrate文件(不用移除整个文件夹)，然后重来 问题：manytomanyfeild没有默认值django admin gives warning “Field ‘X’ doesn’t have a default value” 问题：添加元属性发生错误12raise InternalError(errno, errorvalue)django.db.utils.InternalError: (1017, \"Can't find file: '.\\\\lab_data\\\\people_patent_prizes.frm' (errno: 2 -No such file or directory)\") {模型类中增加class Meta:db_table=’People’使数据库中对应的表名修改成了People，原来的表间联系可能破坏了}解决方案：删除所有migrate文件(不用移除整个文件夹)，然后重来 问题：表中字段不存在“Unknown column ‘name’ in ‘field list’” django中创建了表professor继承了表people的字段，并且在后台可以看到，但实际在数据库中不存在（数据库中查询可看到） 出现问题原因： model中编辑的字段没有在数据库对应的表里创建（原因可能是字段是继承自父类，出现的什么问题？） 数据库中查看表中的字段： migration文件出了什么问题？导致没有同步到数据库（表都没创建）解决方案1：在数据库中手动添加没有创建的字段alter table bigdata_professor add column name varchar(6); 再次查看表中字段： 再次运行django服务器，后台添加name字段时就不会出错了。 解决方案2：先删除整个migrations文件夹，再Python manage.py makemigrations,再python manage.py migrate 这样表就可以重新建立成功了！（可以查询到django中新建的表bigdata_professor….） Note: 成功后最好把之前删除的文件夹migrations重新建一个（app中的） 只删除migration文件可能不会出现这个问题：No migrations to apply. Your models have changes that are not yet reflected in a migration, and so won’t be applied. Run ‘manage.py makemigrations’ to make new migrations, and then re-run ‘manage.py migrate’ to apply them. 我了个去，都不知道为啥migration文件会出问题，删除后再操作就没事了，可能是（在makemigrations）之前先进行了migrate操作？[Django Models (1054, “Unknown column in ‘field list’”)] 问题：表不存在或者No migrations to apply “Table ‘lab_data.bigdata_resdir’ doesn’t exist” 模型中建立新表后，makemigrations成功，但是migrate出现错误: python manage.py migrateOperations to …:Apply all migrations: …No migrations to apply.(即使实际上明明makemigrations成功，并且有许多migrations可以应用) Your models have changes that are not yet reflected in a migration, and so won’t be applied. Run ‘manage.py makemigrations’ to make new migrations, and then re-run ‘manage.py migrate’ to apply them. 按照提示重新makemigration后migration文件就不会创建新表了，在数据库中表也的确没有新建。原因： Sounds like your initial migration was faked because the table already existed (probably with an outdated schema): “This will make a new initial migration for your app. Now, when you run migrate,Django will detect that you have an initial migration and that the tables it wants to create already exist, and will mark the migration as already applied.”Otherwise you would get an no-such-table error.[No migrations to apply, even though there are migrations to apply] 也可能是之前按照某个说明执行了一次python manage.py migrate –fake导致的。–fake 的含义是不执行该迁移脚本但是标记该脚本已经被执行过。导致之后无法正常进行迁移。[Django 1.7 中 migrate 无法执行而且表不存在的解决方案]解决方案：方法1. In MySQL Database delete row ‘app_name’ from the table ‘django_migrations’.打开mysql command line client, 进入创建好的数据库use databasename; 查看表select * from django_migration; 发现将要执行的迁移脚本的 id 已经添加在表中了，将其删除即可，即删除最新一次app_name对就的id行。 Delete all migration files in migrations folder. Try again python manage.py makemigrations and python manage.py migrate command.[Django 1.7 - “No migrations to apply” when run migrate after makemigrations]方法2：移除整个migrations文件夹，重新makemigrations和migrate。之后就会自动创建了： 方法3：实在不行，只能drop database，再重新建立了。 问题：外键修改成多对多错误ValueError: Cannot alter field bigdata.Postgraduate.publisher into bigdata.Postgraduate.publisher - they are not compatible types (you cannot alter to or from M2M fields, or add or remove through= on M2M fields) {这个错误是由将模型Postgraduate中的publisher字段从ForeignKey修改成ManyToManyField引起的}解决方案：删除所有migrations文件，重新makemigrations和migrate[foreignkey error: Django migration error :you cannot alter to or from M2M fields, or add or remove through= on M2M fields] 数据库注册到site管理错误TypeError: init() missing 2 required positional arguments : ‘model’ and ‘admin_site’ class DirectionsInline(inlineBase, admin.ModelAdmin): model = Directions inlines = [ImagesInline, ]admin.site.register(Directions, DirectionsInline) 解决：原因可能是继承admin.ModelAdmin的类中不能有model = * 数据库权限错误django.db.utils.operationalerror:&lt;1045,”access denied for user root@localhost using password yes&gt;解决方案1：django setting.py文件中设置的database用户名或者密码错了，修改一下就可以了或者是django运行项目时用的不是settings.py文件，这个在os.environ.setdefault(“DJANGO_SETTINGS_MODULE”, “labsite.settings”)中设置 其它方案：Access denied for user ‘root’@’localhost’ (using password: YES) mysql Access denied for user root@localhost错误解决方法总结(转)ERROR 1045 (28000): Access denied for user ‘root’@’localhost’ (using password: NO)MySQL Forums ::Install &amp; Repo ::ERROR 1045 (28000): Access denied for user ‘root’@’localhost’ (using password: NO)django.db.utils.operationalerror:&lt;2003, “can’t connect to mysql server on ‘127.0.0.1’(winerror 10061] No connection could be made because the target machine actively refused it)”)settings.py中设置的host和port如下‘HOST’: ‘127.0.0.1’,’PORT’: ‘3306’ 如改动port为其它，可能导致该问题其它问题：1.Error: Tablespace for table xxx exists. Please DISCARD the tablespace before IMPORT django.db.utils.ProgrammingError: (1146, “Table ‘lab_data.django_migrations’ doesn’t exist”)3.django.db.utils.InternalError: (1050, “Table ‘l ab_data.django_migrations‘already exists”) 1&gt;两个模型的数据库表名设置成一样的了class Meta: db_table = ‘WorkExp1’2&gt;python manage.py migrate –fakequestion:django.db.utils.InternalError: (1050, “Table ‘s_user_address’ already exists”) answer:./manage.py migrate myapp –fake 指定app 跳转//(py3_django) python@ubuntu:~/project/dailyfresh$ python manage.py migrate –fake –fakeOperations to perform: Synchronize unmigrated apps: staticfiles, messages, haystack, tinymce Apply all migrations: admin, df_cart, df_goods, djcelery, sessions, userinfo, auth, contenttypesSynchronizing apps without migrations: Creating tables… Running deferred SQL… Installing custom SQL…Running migrations: Rendering model states… DONE Applying userinfo.0001_initial… FAKED Applying df_goods.0001_initial… FAKED Applying df_cart.0001_initial… FAKED Applying djcelery.0001_initial… FAKED Applying djcelery.0002_auto_20170825_1331… FAKED Applying djcelery.0003_auto_20170827_0832… FAKED Applying djcelery.0004_auto_20170827_1256… FAKED Applying djcelery.0005_auto_20170828_0819… FAKED Applying djcelery.0006_auto_20170828_0826… FAKED Applying djcelery.0007_auto_20170828_1725… FAKED Applying djcelery.0008_auto_20170831_0830… FAKED Applying djcelery.0009_auto_20170831_1510… FAKED Applying djcelery.0010_auto_20170831_1514… FAKED Applying djcelery.0011_auto_20170831_1526… FAKED Applying djcelery.0012_auto_20170831_1532… FAKED Applying djcelery.0013_auto_20170831_1539… FAKED Applying djcelery.0014_auto_20170831_1552… FAKED Applying djcelery.0015_auto_20170831_1608… FAKED(py3_django) python@ubuntu:~/project/dailyfresh$ python manage.py migrate Operations to perform: Synchronize unmigrated apps: tinymce, haystack, messages, staticfiles Apply all migrations: djcelery, auth, userinfo, admin, contenttypes, df_cart, sessions, df_goodsSynchronizing apps without migrations: Creating tables… Running deferred SQL… Installing custom SQL…Running migrations: No migrations to apply. Your models have changes that are not yet reflected in a migration, and so won’t be applied. Run ‘manage.py makemigrations’ to make new migrations, and then re-run ‘manage.py migrate’ to apply them. (py3_django) python@ubuntu:~/project/dailyfresh$ python manage.py migrateOperations to perform: Synchronize unmigrated apps: messages, staticfiles, tinymce, haystack Apply all migrations: djcelery, df_goods, admin, df_cart, contenttypes, sessions, userinfo, authSynchronizing apps without migrations: Creating tables… Running deferred SQL… Installing custom SQL…Running migrations: Rendering model states… DONE Applying df_cart.0001_initial… OK(py3_django) python@ubuntu:~/project/dailyfresh$","categories":[{"name":"django","slug":"django","permalink":"http://smartfice.com/categories/django/"}],"tags":[{"name":"django","slug":"django","permalink":"http://smartfice.com/tags/django/"},{"name":"mysql","slug":"mysql","permalink":"http://smartfice.com/tags/mysql/"}]},{"title":"Django middleware","slug":"middleware","date":"2017-10-08T09:18:52.455Z","updated":"2017-10-08T09:18:52.451Z","comments":true,"path":"middleware/","link":"","permalink":"http://smartfice.com/middleware/","excerpt":"","text":"Django中间件是一个轻量级、底层的插件系统，可以介入Django的请求和响应处理过程，修改Django的输入或输出。中间件为设计开发者提供了一种无侵入式的开发方式。在middleware.py文件中定义中间件类： init(self) :服务器响应第一个请求的时候调用。 process_request(self, request)(每个请求上调用,返回None或者HttpResponse对象)：是产生request对象,进行url匹配之前调用 process_view(self, request, view_func, view_args, *view_kwargs)（每个请求上调用,返回None或者HttpResponse对象 ）:是url匹配之后,调用视图函数之前. process_response(self, request, response)（每个请求上调用,返回HttpResponse对象 ）:视图函数调用之后，内容返回给浏览器之前。 process_exception(self, request, exception)（每个请求上调用,返回HttpResponse对象 ）:视图函数出现异常，会调用这个函数如果多个中间件类包含process_exception函数的时候，调用的顺序跟注册的顺序是相反的 注册中间件类：settings.py MIDDLEWARE_CLASSES = [ ]比如我们要做一个 拦截器，发生有恶意访问网站的人，就拦截他！Django中间件实现拦截器 JavaWeb Struts2的拦截器我们都能很熟悉，在请求交给Action处理之前，先在拦截器中处理，处理完之后再交给Action。在Django中如何实现相同的效果? 在process_request方法中，返回值为HttpResponse类型的对象的时候不交给普通的控制器处理，直接返回给浏览器，返回值为None的时候，请求处理完之后交给普通的控制器处理。 使用request对象的META属性：request.META[‘REMOTE_ADDR’] 获取访问者的ip 假如我们通过一种技术，比如统计一分钟访问页面数，太多就把他的 IP 加入到黑名单 BLOCKED_IPS（这部分没有提供代码，主要讲中间件部分）项目 文件名 zscf 1234class BlockedIpMiddleware(object): def process_request(self, request): if request.META['REMOTE_ADDR'] in getattr(settings, \"BLOCKED_IPS\", []): return http.HttpResponseForbidden('&lt;h1&gt;Forbidden&lt;/h1&gt;') 这里的代码的功能就是 获取当前访问者的 IP (request.META[‘REMOTE_ADDR’])，如果这个 IP 在黑名单中就拦截，如果不在就返回 None (函数中没有返回值其实就是默认为 None)，把这个中间件的 Python 路径写到settings.py中 1234MIDDLEWARE_CLASSES = ( 'zscf.middleware.BlockedIpMiddleware', ...其它的中间件) Django 会从 MIDDLEWARE_CLASSES 中按照从上到下的顺序一个个执行中间件中的 process_request 函数，而其中 process_response 函数则是最前面的最后执行。 再比如，我们在网站放到服务器上正式运行后，DEBUG改为了 False，这样更安全，但是有时候发生错误不能显示错误详情页面，有没有办法处理好这两个事情呢？ 普通访问者看到的是友好的报错信息 管理员看到的是错误详情，以便于修复 BUG 当然可以有，利用中间件就可以做到！代码如下：12345678import sysfrom django.views.debug import technical_500_responsefrom django.conf import settings class UserBasedExceptionMiddleware(object): def process_exception(self, request, exception): if request.user.is_superuser or request.META.get('REMOTE_ADDR') in settings.INTERNAL_IPS: return technical_500_response(request, *sys.exc_info()) 把这个中间件像上面一样，加到你的 settings.py 中的 MIDDLEWARE_CLASSES 中，可以放到最后，这样可以看到其它中间件的 process_request的错误。","categories":[{"name":"django","slug":"django","permalink":"http://smartfice.com/categories/django/"}],"tags":[{"name":"django","slug":"django","permalink":"http://smartfice.com/tags/django/"},{"name":"python","slug":"python","permalink":"http://smartfice.com/tags/python/"}]},{"title":"images","slug":"images/index","date":"2017-10-05T13:58:38.000Z","updated":"2017-10-05T13:58:38.059Z","comments":true,"path":"images/index/","link":"","permalink":"http://smartfice.com/images/index/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"python","slug":"python","date":"2017-09-28T12:29:10.000Z","updated":"2017-09-28T12:38:19.249Z","comments":true,"path":"python/","link":"","permalink":"http://smartfice.com/python/","excerpt":"","text":"欢迎来到我的技术","categories":[],"tags":[]}]}